The argument is from first principles, and goes like this: The world is _computationally irreducible_. The world state evolves always according to a bunch of inviolable rules. The way to be "intelligent" is to build a model of those rules, set some initial conditions, and then "run" the model and see what happens. The problem with this kind of intelligence is that you have to somehow "keep up" with the world. The world runs faster than you do, so you have to cheat and leave out some unnecessary computations. You remove some stuff and optimize some stuff and try again, and again, and again. Eventually you have a model that can get ahead of the world in useful ways. There seems to be a fundamental tension between speed, generality, and precision. A perfectly general and precise model evolves at the speed of the world. A super precise model can either be fast or general. A super general model can't be very precise.

What you're left with is something like a neural network, a model that can get really far ahead of the world but also really struggles with the formal details.